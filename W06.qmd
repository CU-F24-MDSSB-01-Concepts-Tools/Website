---
title: "W#06: Epidemic Modeling, Calculus, Linear Model, Fitting a Linear Model"
author: Jan Lorenz
format: 
  revealjs: 
    slide-number: true
    chalkboard: 
      buttons: true
    preview-links: true
    logo: img/ConstructorUniversity.png
    footer: "[CU-F23-MDSSB-DSCO-02: Data Science Concepts](https://github.com/CU-F23-MDSSB-01-Concepts-Tools)"
bibliography: "/home/janlo/Documents/literature/litlorenz_zot.bib"
---

```{r}
#| include: false
library(tidyverse)
```

# Epidemic Modeling


## SIR model  {.smaller  background-color="khaki"}

- Assume a population of $N$ individuals.  
- Individuals can have different states, e.g.: **S**usceptible, **I**nfectious, **R**ecovered, ...
- The population divides into compartments of these states which change over time, e.g.:   $S(t), I(t), R(t)$ *number of susceptible, infectious, recovered* individuals

Now we define dynamics like

![](https://upload.wikimedia.org/wikipedia/commons/3/30/Diagram_of_SIR_epidemic_model_states_and_transition_rates.svg)

where the numbers on the arrows represent transition probabilities. 

## Agent-based Simulation {.smaller  background-color="khaki"}

**Agent-based model**: Individual agents are simulated and interact with each other.  
Explore and analyze with **computer simulations**.

A tool: **NetLogo** <https://ccl.northwestern.edu/netlogo/>

![](http://netlogoweb.org/assets/images/desktopicon.png)

We look at the model **"Virus on a Network"** from the model library.

## Virus on a Network: 6 links, initial {.smaller  background-color="khaki"}

Agents connected in a **network** with on average 6 links per agent. 3 are infected initially.

![](img/netlogo_SIR_6links_init.png)


## Virus on a Network: 6 links, final {.smaller  background-color="khaki"}

The outbreak dies out after some time.

![](img/netlogo_SIR_6links_final.png)


## Virus on a Network: 15 links, initial {.smaller  background-color="khaki"}

Repeat the simulation with 15 links per agent. 3 are infected initially.
![](img/netlogo_SIR_15links_init.png)


## Virus on a Network: 15 links, final {.smaller  background-color="khaki"}

The outbreak had infected most agents.

![](img/netlogo_SIR_15links_final.png)


## SI model {.smaller  background-color="khaki"}

Now, we only treat the SI part of the model. We ignore recovery. 

- People who are susceptible can become infected through contact with infectious
- People who are infectious stay infectious 

The parameter $\beta$ is the average number of contacts per unit time multiplied with the probability that an infection happens during such a contact. 


## SI-model: Simulation in R {.smaller background-color="khaki"}

- We produce a vector of length $N$ with entries representing the state of each individual as `"S"` or `"I"`. 
- We model the random infection process in each step of unit time

**Setup**

Parameters: $N=150, \beta=0.3$, a function to produce randomly infect individuals

```{r}
#| echo: true
#| output-location: column
N <- 150
beta <- 0.3
randomly_infect <- function(N, prob) { 
 runif(N) < prob 
 # Gives a logical vector of length N
 # where TRUE appears with probability beta
}
# Test
randomly_infect(N, beta) |> head() # First 6
```

```{r}
#| echo: true
#| output-location: column
init <- rep("S",N) # All susceptible
init[1] <- "I" # Infect one individual
init |> head() # First 6
``` 


## SI-model: Simulation in R {.smaller background-color="khaki"}

Iteration over 75 time steps.

```{r}
#| echo: true
#| output-location: column
#| cache: true
tmax <- 75
sim_run <- list(init) # list with one element
# This list will collect the states of 
# all individuals over tmax time steps 
for (i in 2:tmax) {
 # Every agents has a contact with a random other
 contacts <- sample(sim_run[[i-1]], size = N)
 sim_run[[i]] <- if_else( # vectorised ifelse
  # conditions vector: contact is infected
  # and a random infection happens
  contacts == "I" & randomly_infect(N, beta), 
  true = "I", 
  false = sim_run[[i-1]]
  ) # otherwise state stays the same
}
sim_output <- tibble( # create tibble for ggplot
 # Compute a vector with length tmax 
 # with the count of "I" in sim_run list
 t = 0:(tmax-1), # times steps
 # count of infected, notice map_dbl
 infected = map_dbl(sim_run, \(x) sum(x == "I"))) 
sim_output |> 
 ggplot(aes(t,infected)) + geom_line() +
 theme_minimal(base_size = 20)
```

## SI-model: Simulation in R {.smaller background-color="khaki"}

Run with $N = 10000$

```{r}
#| echo: true
#| output-location: column
#| cache: true
N <- 10000
init <- rep("S",N) # All susceptible
init[1] <- "I" # Infect one individual
tmax <- 75
sim_run <- list(init) # list with one element
# This list will collect the states of 
# all individuals over tmax time steps 
for (i in 2:tmax) {
 # Every agents has a contact with a random other
 contacts <- sample(sim_run[[i-1]], size = N)
 sim_run[[i]] <- if_else( # vectorised ifelse
  # conditions vector: contact is infected
  # and a random infection happens
  contacts == "I" & randomly_infect(N, beta), 
  true = "I", 
  false = sim_run[[i-1]]
  ) # otherwise state stays the same
}
sim_output <- tibble( # create tibble for ggplot
 # Compute a vector with length tmax 
 # with the count of "I" in sim_run list
 t = 0:(tmax-1), # times steps
 # count of infected, notice map_dbl
 infected = map_dbl(sim_run, \(x) sum(x == "I"))) 
sim_output |> 
 ggplot(aes(t,infected)) + geom_line() +
 theme_minimal(base_size = 20)
```



## New programming concepts {.smaller}

From base R:

`runif` random numbers from uniform distribution  
`sample` random sampling from a vector  
`for` loop over commands with index (`i`) taking values of a vector (`2:tmax`) one by one
`if_else` vectorized version of conditional statements


# Calculus

The mathematics of the **change** and the **accumulation** of quantities

## Motivation:  SI model with <br> population compartments {background-color="khaki"}

Two compartments:   
$S(t)$ is the number of susceptible people at time $t$.  
$I(t)$ is the number of infected people at time $t$.  

It always holds $S(t) + I(t) = N$. (The total population is constant.)

## How many infections per time? {.smaller background-color="khaki"}

The **change** of the number of infectious

$$\frac{dI}{dt} = \underbrace{\beta}_\text{infection prob.} \cdot \underbrace{\frac{S}{N}}_\text{frac. of $S$ still there} \cdot \underbrace{\frac{I}{N}}_\text{frac. $I$ to meet} \cdot N = \frac{\beta\cdot S\cdot I}{N}$$

where $dI$ is the *change* of $I$ (the newly infected here) and $dt$ the time interval. 

. . . 

**Interpretation:** The newly infected are from the fraction of susceptible *times* the probability that they meet an infected *times* the infection probability *times* the total number of individuals.   
[Same logic as our Simulation in R!]{style='color:red;'}

. . . 

Using $S = N - I$ we rewrite

$$\frac{dI}{dt} = \frac{\beta (N-I)I}{N}$$


## Ordinary differential equation {background-color="aquamarine"}

We interpret $I(t)$ as a function of time which gives us the number of infectious at each point in time. The change function is now

$$\frac{dI(t)}{dt} = \frac{\beta (N-I(t))I(t)}{N}$$

and $\frac{dI(t)}{dt}$ is also called the **derivative** of $I(t)$. 

## Derivatives {.smaller  background-color="aquamarine"}

::: {.columns}

::: {.column width='70%'}
- The *derivative* of a function is also a function with the same domain. 
- Measures the sensitivity to change of the function output when the input changes (a bit)
- Example from physics: The derivative of the *position* of a moving object is its *speed*. The derivative of its speed is its *acceleration.* 
- Graphically: The derivative is the *slope* of a *tangent line* of the graph of a function. 
:::

::: {.column width='30%'}
![](https://upload.wikimedia.org/wikipedia/commons/2/2d/Tangent_function_animation.gif)
:::

:::

## Differentiation {.smaller  background-color="aquamarine"}
 
is the process to compute the derivative. For parameters $a$ and $b$ and other functions $g$ and $h$, rules of differentiation are

:::{.columns}
:::{.column width="30%"}
Function $f(x)$
::: 
:::{.column width='70%'}
Its derivative $\frac{df(x)}{dx}$ or  $\frac{d}{dx}f(x)$ or $f'(x)$
:::
:::

:::{.columns}
:::{.column width="30%"}
$a\cdot x$

$b$

$x^2,\ x^{-1} = \frac{1}{x},\ x^k$

$g(x) + h(x)$

$g(x)\cdot h(x)$

$g(h(x))$

$e^x,\ 10^x  = e^{\log(10)x}$

$\log(x)$
::: 
:::{.column width='70%'}
:::{.fragment fragment-index=1}
$a$
:::
:::{.fragment fragment-index=2}
$0$
:::
:::{.fragment fragment-index=3}
$2\cdot x,\ -x^{-2} = -\frac{1}{x^2},\ k\cdot x^{k-1}$
:::
:::{.fragment fragment-index=4}
$g'(x) + h'(x)$
:::
:::{.fragment fragment-index=5}
$g'(x)\cdot h(x) + g(x)\cdot h'(x)$ (product rule)
:::
:::{.fragment fragment-index=6}
$g'(h(x))\cdot h'(x)$ (chain rule)
:::
:::{.fragment fragment-index=7}
$e^x,\ 10^x = \log(10)\cdot10^x$
:::
:::{.fragment fragment-index=}
$\frac{1}{x}$ (A surprising relation to me at least)
:::
:::
:::

## Differential equation {.smaller  background-color="aquamarine"}

In a differential equation the *unknown* is a function!

We are looking for a function which derivative is a function of the function itself. 

**Example: SI-model**

$$\frac{dI(t)}{dt} = \frac{\beta (N-I(t))I(t)}{N}$$

Which function $I(t)$ fulfills this equation?

The **analytical solution**^[Can you check that this is correct? Compute $I'(t)$ ($=\frac{dI(t)}{dt}$) and check if $I'(t) = \frac{\beta (N-I(t))I(t)}{N}$. It is a bit of work, but try it! Let me know, if you want a solution.] 

$I(t) = \frac{N}{1 + (\frac{N}{I(0)} - 1)e^{-\beta t}}$

Which is called the *logistic equation*. 
Note, we need to specify the initial number of infectious individuals $I(0)$. 

## SI-model: Logistic Equation {.smaller  background-color="khaki"}

$I(t) = \frac{N}{1 + (\frac{N}{I(0)} - 1)e^{-\beta t}}$

Plot the equation for $N = 10000$, $I_0 = 1$, and $\beta = 0.3$

```{r}
#| echo: true
#| fig-height: 3
N <- 10000
I0 <- 1
beta <- 0.3
ggplot() + 
 geom_function( fun = function(t) N / (1 + (N/I0 - 1)*exp(-beta*t)) ) + 
 xlim(c(0,75))
```

## SI-model: Numerical integration {.smaller background-color="khaki"}

Another way of solution using, e.g., using *Euler's method*. 

We compute the solution step-by-step using increments of, e.g. $dt = 1$.

```{r}
#| echo: true
#| output-location: column
N <- 10000
I0 <- 1
dI <- function(I,N,b) b*I*(N - I)/N
beta <- 0.3
dt <- 1 # time increment, 
# supposed to be infinitesimally small
tmax <- 75
t <- seq(0,tmax,dt) 
# this is the vector of timesteps
It <- I0 # this will become the vector 
# of the number infected I(t) over time
for (i in 2:length(t)) { 
 # We iterate over the vector of time steps 
 # and incrementally compute It
 It[i] = It[i-1] + dt * dI(It[i-1], N, beta) 
 # This is called Euler's method
}
tibble(t, It) |> ggplot(aes(t,It)) + 
 geom_function( 
  fun = function(t) N / (1 + (N/I0 - 1)*exp(-beta*t))) + 
 # Analytical solution for comparison
 geom_line(color = "red") + # The numerical solution in black
 theme_minimal(base_size = 20)
```

Why do the graphs deviate? [The step size must be "infinitely" small]{.fragment}

## Numerical integration with smaller $dt$ {.smaller background-color="khaki"}

We compute the solution step-by-step using small increments of, e.g. $dt = 0.01$.

```{r}
#| echo: true
#| output-location: column
N <- 10000
I0 <- 1
dI <- function(I,N,b) b*I*(N - I)/N
beta <- 0.3
dt <- 0.01 # time increment, 
# supposed to be infinitesimally small
tmax <- 75
t <- seq(0,tmax,dt) 
# this is the vector of timesteps
It <- I0 # this will become the vector 
# of the number infected I(t) over time
for (i in 2:length(t)) { 
 # We iterate over the vector of time steps 
 # and incrementally compute It
 It[i] = It[i-1] + dt * dI(It[i-1], N, beta) 
 # This is called Euler's method
}
tibble(t, It) |> ggplot(aes(t,It)) + 
 geom_function( 
  fun = function(t) N / (1 + (N/I0 - 1)*exp(-beta*t))) + 
 # Analytical solution for comparison
 geom_line(color = "red") + # The numerical solution in black
 theme_minimal(base_size = 20)
```


## Mechanistic model {.smaller background-color="khaki"}

The SI model is a potential answer to the **mechanistic question** *How do epidemics spread?*

The examples above show 3 different ways to explore the model:

- *Agent-based simulation*
  - We model every individual explicitly
  - Simulation involve random numbers! So simulation runs can be different!

. . .

- *Numerical integration* of differential equation
  - Needs a more abstract concept of *compartments*

. . . 

- *Analytical solutions* of differential equation
  - often not possible (therefore numerical integration is common)


## Differentiation with data

[**We can do calculus operations with data!**]{style='color:red;'}

In empirical data we can compute the increase in a vector with the function `diff`:

```{r}
#| echo: true
x <- c(1,2,4,5,5,3,0)
diff(x)
```

. . . 

More convenient in a data frame is to use `x - lag(x)` because the vector has the same length.

```{r}
#| echo: true
x - lag(x)
```


## The diff of our simulation output {.smaller}

```{r}
#| echo: true
#| fig-height: 2
g1 <- sim_output |> ggplot(aes(x = t)) + geom_line(aes(y = infected))
g1
g2 <- sim_output |> 
 mutate(derivative_infected = infected - lag(infected)) |> 
 ggplot(aes(x = t)) + geom_line(aes(y = derivative_infected))
g2
```

## 2nd derivative: Change of change 

```{r}
#| echo: true
#| fig-height: 2
g3 <- sim_output |> 
 mutate(derivative_infected = infected - lag(infected),
        derivative2_infected = derivative_infected - lag(derivative_infected)) |> 
 ggplot(aes(x = t)) + geom_line(aes(y = derivative2_infected))
g3
```

In empirical data: Derivatives of higher order tend to show fluctuation


## Interpretation in SI-model {.smaller  background-color="khaki"}

```{r}
#| fig-height: 3
library(patchwork)
g1 + g2 + g3
```

- $I(t)$ total number of infected
- $I'(t)$ number of new cases per day (time step)
- $I''(t)$ how the number of new cases has changes compared to yesterday
  - [2nd derivatives are a good early indicator for the end of a wave.]{style='color:red;'}

## Integration {.smaller background-color="aquamarine"}

The **integral** of the daily new cases from the beginning to day $s$ is $\int_{-\infty}^s f(t)dt$ and represents the total cases at day $s$. 

- The integral of a function $f$ up to time $s$ is also called the **anti-derivative** $F(s) = \int_{-\infty}^s f(t)dt$.
    - The symbol $\int$ comes from an S and means "sum".
- Compute the anti-derivative of data vector with `cumsum`.

```{r}
#| echo: true
x <- c(1,2,4,5,5,3,0)
cumsum(x)
```

- Empirically: Derivatives tend to become noisy, while integrals tend to become smooth.   


## The fundamental theorem of calculus {.smaller background-color="aquamarine"}

**The integral of the derivative is the function itself.**


This is not a proof but shows the idea:
```{r}
#| echo: true
f <- c(1,2,4,5,5,3,0)
antiderivative <- cumsum(f)
antiderivative
diff(c(0, antiderivative)) 
# We have to put 0 before to regain the full vector
derivative <- diff(f)
derivative
cumsum(c(1,derivative)) 
# We have to put in the first value (here 1) 
# manually because it was lost during the diff
```


# Linear Model
The first work-horse to explore relations between numerical variables

## Different purposes of models {.smaller background-color="khaki"}

**Agent-based models** and **differential equations** are usually used to **explain** the **dynamics** of one or more variables typically over time. They are used to answer [*mechanistic questions*]{style='color:blue;'}.

. . . 

In the following we treat **variable-based models** which we use to 

- **explain** relations between variables
- make **predictions**

These are often used to answer [*inferential*]{style='color:blue;'} and [*predictive questions*]{style='color:blue;'}.   
(With experimental or more theoretical effort also for [*causal questions*]{style='color:blue;'}.)

First, we focus on linear models.

## Hello again penguins! {.scrollable .smaller}

We use the dataset [Palmer Penguins](https://allisonhorst.github.io/palmerpenguins/)

Chinstrap, Gentoo, and Adélie Penguins

![](https://upload.wikimedia.org/wikipedia/commons/0/08/South_Shetland-2016-Deception_Island%E2%80%93Chinstrap_penguin_%28Pygoscelis_antarctica%29_04.jpg){height=200}
![](https://upload.wikimedia.org/wikipedia/commons/0/00/Brown_Bluff-2016-Tabarin_Peninsula%E2%80%93Gentoo_penguin_%28Pygoscelis_papua%29_03.jpg){height=200}
![](https://upload.wikimedia.org/wikipedia/commons/e/e3/Hope_Bay-2016-Trinity_Peninsula%E2%80%93Ad%C3%A9lie_penguin_%28Pygoscelis_adeliae%29_04.jpg){height=200}


```{r}
library(palmerpenguins)
penguins
```

## Body mass in grams

```{r}
#| echo: true
penguins |>
  ggplot(aes(body_mass_g)) +
  geom_histogram()
```

## Flipper length in millimeters

```{r}
#| echo: true
penguins |>
  ggplot(aes(flipper_length_mm)) +
  geom_histogram()
```

## Relate variables as a line {.smaller background-color="aquamarine"}

A *line* is a shift-scale transformation of the identity function usually written in the form 

$$f(x) = a\cdot x + b$$

where [$a$ is the *slope*]{style="color:red;"}, [$b$ is the *intercept*]{style="color:blue;"}.^[This a scale and a shift in the $y$ direction. Note: For lines there are always an analog transformations on the $x$ direction.]

```{r}
#| echo: true
#| output-location: column
a <- 0.5
b <- 1
func <- function(x) a*x + b
ggplot() + geom_function(fun = func, size = 2) +
 # Set axis limits and make axis equal
	xlim(c(-0.5,2)) + ylim(c(0,2)) + coord_fixed() + 
	geom_line( # intercept line:
	 data=tibble(x=c(0,0),y=c(0,1)), 
	 mapping = aes(x,y), 
	 color = "blue", size = 2) +
	geom_line( # slope:
	 data=tibble(x=c(1.5,1.5),y=c(1.25,1.75)), 
	 mapping = aes(x,y), 
	 color = "red", size = 2) +
	geom_line( # x-interval of length one:
	 data=tibble(x=c(0.5,1.5),y=c(1.25,1.25)), 
	 mapping = aes(x,y), color = "gray") +
	theme_classic(base_size = 24)
```

## Penguins: Linear model {.smaller}

**Flipper length** as a function of **body mass**.

```{r}
#| echo: true
#| output-location: column
#| fig-height: 9
penguins |>
 ggplot(aes(x = body_mass_g, 
            y = flipper_length_mm)) +
 geom_point() +
 geom_smooth(method = "lm", 
             se = FALSE) + 
 theme_classic(base_size = 24)
```

## Penguins: A smooth line {.smaller}

**Flipper length** as a function of **body mass** with `loess`^[loess = locally estimated scatterplot smoothing] smoothing. 

```{r}
#| echo: true
#| output-location: column
#| fig-height: 7
penguins |>
 ggplot(aes(x = body_mass_g, 
            y = flipper_length_mm)) +
 geom_point() +
 geom_smooth(method = "loess") + 
 theme_classic(base_size = 24)
```

This is a less theory-driven and more data-driven model. Why?    
[We don't have a simple mathematical form of the function.]{.fragment}

## Terminology variable-based models {.smaller background-color="khaki"}

- **Response variable:**^[Also **dependent variable** in statistics or empirical social sciences.] Variable whose behavior or variation you are trying to understand, on the y-axis
- **Explanatory variable(s):**^[Also **independent variable(s)** in statistics or empirical social sciences.] Other variable(s) that you want to use to explain the variation in the response, on the x-axis
- **Predicted value:** Output of the model function. 
  - The model function gives the **(expected) average value** of the response variable conditioning on the explanatory variables
  - **Residual(s):** A measure of how far away a case is from its predicted value (based on the particular model)   
    Residual = Observed value - Predicted value  
    The residual tells how far above/below the expected value each case is

## More explanatory variables {.smaller}

How does the relation between flipper length and body mass change with different species?

```{r}
#| echo: true
#| output-location: column
#| fig-height: 7
penguins |>
 ggplot(aes(x = body_mass_g, 
            y = flipper_length_mm, 
            color = species)) +
 geom_point() +
 geom_smooth(method = "lm",
             se = FALSE) + 
 theme_classic(base_size = 24)
```

## ggplot-hint: How to color penguins but keep one model? {.smaller}

Put the mapping of the color aesthetic into the `geom_point` command. 

```{r}
#| echo: true
#| output-location: column
#| fig-height: 6
penguins |>
 ggplot(aes(x = body_mass_g, 
            y = flipper_length_mm)) +
 geom_point(aes(color = species)) +
 geom_smooth(method = "lm",	se = FALSE) + 
 theme_classic(base_size = 24)
```

## Beware of Simpson's paradox {.smaller background-color="aquamarine"} 

Slopes for all groups can be in the opposite direction of the main effect's slope!

![](https://upload.wikimedia.org/wikipedia/commons/f/fb/Simpsons_paradox_-_animation.gif)
::: aside
Source: <https://upload.wikimedia.org/wikipedia/commons/f/fb/Simpsons_paradox_-_animation.gif>
:::


## The paradox is real! {.smaller}

How does the relation between bill length and body mass change with different species?

```{r}
#| echo: true
#| output-location: column
#| fig-height: 7
penguins |>
 ggplot(aes(x = bill_length_mm, 
            y = bill_depth_mm)) +
 geom_point(aes(color = species)) +
 geom_smooth(mapping = aes(color = species),
             method = "lm",
             se = FALSE) + 
 geom_smooth(method = "lm",
													se = FALSE) + 
 theme_classic(base_size = 24)
```


## Models - upsides and downsides {.smaller background-color="khaki"}

- Models can reveal patterns that are not evident in a graph of the data. This is an advantage of modeling over simple visual inspection of data.
  - How would you visualize dependencies of more than two variables?
- The risk is that a model is imposing structure that is not really there in the real world data. 
  - People imagined animal shapes in the stars. This is maybe a good model to detect and memorize shapes, but it has nothing to do with these animals.
  - Every model is a simplification of the real world, but there are good and bad models (for particular purposes). 
  - A skeptical (but constructive) approach to a model is always advisable. 
  
  
## Variation around a model {.smaller background-color="khaki"}

... is as interesting and important as the model!

*Statistics is the explanation of uncertainty of variation in the context of what remains unexplained.*

- The scattered data of flipper length and body mass suggests that there maybe other factors that account for some parts of the variability. 
- Or is it randomness?
- Adding more explanatory variables can help (but need not)

## *All models are wrong ...* {.smaller background-color="khaki"}

*... but some are useful.* (George Box)


Extending the range of the model: 

```{r}
#| echo: true
#| output-location: column
#| fig-height: 5.5
penguins |>
 ggplot(aes(x = body_mass_g, 
            y = flipper_length_mm)) +
 geom_point() +
 geom_smooth(method = "lm", 
             se = FALSE, 
 												fullrange = TRUE) +
	xlim(c(0,7000)) + ylim(c(0,230)) +
 theme_classic(base_size = 24)
```

- The model predicts that penguins with zero weight still have flippers of about 140 mm on average.
- Is the model useless? [Yes, around zero body mass. No, it works OK in the range of the body mass data.]{.fragment}

## Two model purposes {.smaller background-color="khaki"}

Linear models can be used for:

- **Explanation:** Understand the relationship of variables in a quantitative way.   
*For the linear model, interpret slope and intercept.*
- **Prediction:** Plug in new values for the explanatory variable(s) and receive the expected response value.   
*For the linear model, predict the flipper length of new penguins by their body mass.*

# Fitting Models (Part 1)

Today: The linear model. 

## In R: `tidymodels`

![](https://datasciencebox.org/course-materials/_slides/u4-d02-fitting-interpreting-models/img/tidymodels.png)

:::{.aside}
From <https://datasciencebox.org>
:::

## Our goal

Predict flipper length from body mass

average `flipper_length_mm` $= \beta_0 + \beta_1\cdot$ `body_mass_g`


## Step 1: Specify model

```{r}
#| echo: true
library(tidymodels)
linear_reg()
```

## Step 2: Set the model fitting *engine*

```{r}
#| echo: true
linear_reg() |> 
	set_engine("lm")
```

## Step 3: Fit model and estimate parameters {.smaller}

Only now, the data and the variable selection comes in. 

Use of **formula syntax**

```{r}
#| echo: true
linear_reg() |> 
	set_engine("lm") |> 
	fit(flipper_length_mm ~ body_mass_g, data = penguins)
```

[`parsnip`](http://parsnip.tidymodels.org) is package in `tidymodels` which is to provide a tidy, unified interface to models that can be used to try a range of models. 

:::{.aside}
Note: The fit command does not follow the tidyverse principle the data comes first. Instead, the formula comes first. This is to relate to existing traditions of a much older established way of modeling in base R. 
:::

## What does the output say? {.smaller}

```{r}
#| echo: true
linear_reg() |> 
	set_engine("lm") |> 
	fit(flipper_length_mm ~ body_mass_g, data = penguins)
```

. . .

average `flipper_length_mm` $= 136.72956 + 0.01528\cdot$ `body_mass_g`

. . .

**Interpretation:**   
The penguins have a flipper length of 138 mm plus 0.01528 mm for each gram of body mass (that is 15.28 mm per kg).
Penguins with zero mass have a flipper length of 138 mm. However, this is not in the range where the model was fitted.

## Show output in *tidy* form

```{r}
#| echo: true
linear_reg() |> 
	set_engine("lm") |> 
	fit(flipper_length_mm ~ body_mass_g, data = penguins) |> 
	tidy()
```

## Parameter estimation {.smaller background-color="aquamarine"}

Notation from statistics: $\beta$'s for the population parameters and $\hat\beta$'s for the parameters estimated from the sample statistics. 

$$\hat y = \beta_0 + \beta_1 x$$

Is what we cannot have. ($\hat y$ stands for *predicted value of $y$*. )

. . .

We estimate $\hat\beta_0$ and $\hat\beta_1$ in the model fitting process.

$$\hat y = \hat\beta_0 + \hat\beta_1 x$$

:::{style="background-color:khaki;padding:10px;"}
A typical follow-up data analysis question is what the fitted values $\hat\beta_0$ and $\hat\beta_1$ tell us about the population-wide values $\beta_0$ and $\beta_1$? 

This is the typical [**inferential question**]{style='color:blue}.
::: 


## Fitting Linear Models Part 2

Next week!

